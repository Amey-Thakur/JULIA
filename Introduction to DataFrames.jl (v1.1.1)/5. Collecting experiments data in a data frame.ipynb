{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting experiments data in a data frame\n",
    "\n",
    "### Bogumił Kamiński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>PyPlot.jl configuration:</b></p>\n",
    "    <p>In some environments automatic installation of PyPlot.jl might fail. If you encounter this ussue please refer to <a href=\"https://github.com/JuliaPy/PyPlot.jl#installation\">the PyPlot.jl installation instructions</a>. </p>\n",
    "</div>\n",
    "\n",
    "In particular typically executing the following commands:\n",
    "\n",
    "```\n",
    "using Pkg\n",
    "ENV[\"PYTHON\"]=\"\"\n",
    "Pkg.build(\"PyCall\")\n",
    "```\n",
    "\n",
    "should resolve the PyPlot.jl installation issues. However, on OS X sometimes more configuration steps are required. You can find the detailed instructions [here](https://github.com/JuliaPy/PyPlot.jl#os-x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will run a simple Monte Carlo simulation so show examples how one can work with data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following puzzle.\n",
    "\n",
    "We draw independent random numbers from $U(0,1)$ distribution. On the average, how many draws do we need, till the sum of these numbers exceeds $1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code that runs this experiment once. For tutorial reasons we keep all the generated random numbers and recalculate their sum in each iteration (you can try to improve the efficiency of this code as an exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_e (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sim_e()\n",
    "    draw = Float64[]\n",
    "    while true\n",
    "        push!(draw, rand())\n",
    "        sum(draw) > 1.0 && return draw\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234); # just to make sure we get the same results if we are on the same version of Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run our simulation several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Float64}}:\n",
       " [0.5908446386657102, 0.7667970365022592]\n",
       " [0.5662374165061859, 0.4600853424625171]\n",
       " [0.7940257103317943, 0.8541465903790502]\n",
       " [0.20058603493384108, 0.2986142783434118, 0.24683718661000897, 0.5796722333690416]\n",
       " [0.6488819502093455, 0.010905889635595356, 0.06642303695533736, 0.9567533636029237]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [sim_e() for _ in 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check that each time we finished just when we exceeded $1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 1.3576416751679694\n",
       " 1.026322758968703\n",
       " 1.6481723007108444\n",
       " 1.3257097332563035\n",
       " 1.682964240403202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum.(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 0.5908446386657102\n",
       " 0.5662374165061859\n",
       " 0.7940257103317943\n",
       " 0.7460374998872619\n",
       " 0.7262108768002782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@. sum(res) - last(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looks good so far! (and as a bonus we have just made a small exercise in broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us populate a data frame with the results of our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11.808337 seconds (151.98 M allocations: 4.933 GiB, 33.30% gc time, 5.65% compilation time)\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame()\n",
    "\n",
    "@time for i in 1:10^7\n",
    "    push!(df, (id=i, pos=sim_e()))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the process was quite fast, `push!`-ing data to a `DataFrame` is efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>10,000,000 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>pos</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Vector{Float64}\">Array…</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>[0.646691, 0.112486, 0.276021]</td></tr><tr><th>2</th><td>2</td><td>[0.651664, 0.0566425, 0.842714]</td></tr><tr><th>3</th><td>3</td><td>[0.950498, 0.96467]</td></tr><tr><th>4</th><td>4</td><td>[0.945775, 0.789904]</td></tr><tr><th>5</th><td>5</td><td>[0.82116, 0.0341601, 0.0945445, 0.314926]</td></tr><tr><th>6</th><td>6</td><td>[0.12781, 0.374187, 0.931115]</td></tr><tr><th>7</th><td>7</td><td>[0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169]</td></tr><tr><th>8</th><td>8</td><td>[0.732, 0.299058]</td></tr><tr><th>9</th><td>9</td><td>[0.449182, 0.875096]</td></tr><tr><th>10</th><td>10</td><td>[0.0462887, 0.698356, 0.365109]</td></tr><tr><th>11</th><td>11</td><td>[0.302478, 0.372575, 0.150508, 0.147329, 0.283401]</td></tr><tr><th>12</th><td>12</td><td>[0.404953, 0.499531, 0.658815]</td></tr><tr><th>13</th><td>13</td><td>[0.515627, 0.260715, 0.59552]</td></tr><tr><th>14</th><td>14</td><td>[0.292462, 0.28858, 0.61816]</td></tr><tr><th>15</th><td>15</td><td>[0.66426, 0.753508]</td></tr><tr><th>16</th><td>16</td><td>[0.0368842, 0.643704, 0.401421]</td></tr><tr><th>17</th><td>17</td><td>[0.525057, 0.61201]</td></tr><tr><th>18</th><td>18</td><td>[0.432577, 0.082207, 0.199058, 0.576082]</td></tr><tr><th>19</th><td>19</td><td>[0.218177, 0.362036, 0.204728, 0.932984]</td></tr><tr><th>20</th><td>20</td><td>[0.827263, 0.0992992, 0.6343]</td></tr><tr><th>21</th><td>21</td><td>[0.132715, 0.775194, 0.869237]</td></tr><tr><th>22</th><td>22</td><td>[0.0396356, 0.79041, 0.431188]</td></tr><tr><th>23</th><td>23</td><td>[0.137658, 0.60808, 0.255054]</td></tr><tr><th>24</th><td>24</td><td>[0.498734, 0.0940369, 0.52509]</td></tr><tr><th>25</th><td>25</td><td>[0.265511, 0.110096, 0.834362]</td></tr><tr><th>26</th><td>26</td><td>[0.633427, 0.337865, 0.112987]</td></tr><tr><th>27</th><td>27</td><td>[0.78299, 0.838042]</td></tr><tr><th>28</th><td>28</td><td>[0.0878598, 0.386568, 0.330579, 0.748041]</td></tr><tr><th>29</th><td>29</td><td>[0.265595, 0.291069, 0.612628]</td></tr><tr><th>30</th><td>30</td><td>[0.705766, 0.508363]</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& id & pos\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Array…\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & [0.646691, 0.112486, 0.276021] \\\\\n",
       "\t2 & 2 & [0.651664, 0.0566425, 0.842714] \\\\\n",
       "\t3 & 3 & [0.950498, 0.96467] \\\\\n",
       "\t4 & 4 & [0.945775, 0.789904] \\\\\n",
       "\t5 & 5 & [0.82116, 0.0341601, 0.0945445, 0.314926] \\\\\n",
       "\t6 & 6 & [0.12781, 0.374187, 0.931115] \\\\\n",
       "\t7 & 7 & [0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169] \\\\\n",
       "\t8 & 8 & [0.732, 0.299058] \\\\\n",
       "\t9 & 9 & [0.449182, 0.875096] \\\\\n",
       "\t10 & 10 & [0.0462887, 0.698356, 0.365109] \\\\\n",
       "\t11 & 11 & [0.302478, 0.372575, 0.150508, 0.147329, 0.283401] \\\\\n",
       "\t12 & 12 & [0.404953, 0.499531, 0.658815] \\\\\n",
       "\t13 & 13 & [0.515627, 0.260715, 0.59552] \\\\\n",
       "\t14 & 14 & [0.292462, 0.28858, 0.61816] \\\\\n",
       "\t15 & 15 & [0.66426, 0.753508] \\\\\n",
       "\t16 & 16 & [0.0368842, 0.643704, 0.401421] \\\\\n",
       "\t17 & 17 & [0.525057, 0.61201] \\\\\n",
       "\t18 & 18 & [0.432577, 0.082207, 0.199058, 0.576082] \\\\\n",
       "\t19 & 19 & [0.218177, 0.362036, 0.204728, 0.932984] \\\\\n",
       "\t20 & 20 & [0.827263, 0.0992992, 0.6343] \\\\\n",
       "\t21 & 21 & [0.132715, 0.775194, 0.869237] \\\\\n",
       "\t22 & 22 & [0.0396356, 0.79041, 0.431188] \\\\\n",
       "\t23 & 23 & [0.137658, 0.60808, 0.255054] \\\\\n",
       "\t24 & 24 & [0.498734, 0.0940369, 0.52509] \\\\\n",
       "\t25 & 25 & [0.265511, 0.110096, 0.834362] \\\\\n",
       "\t26 & 26 & [0.633427, 0.337865, 0.112987] \\\\\n",
       "\t27 & 27 & [0.78299, 0.838042] \\\\\n",
       "\t28 & 28 & [0.0878598, 0.386568, 0.330579, 0.748041] \\\\\n",
       "\t29 & 29 & [0.265595, 0.291069, 0.612628] \\\\\n",
       "\t30 & 30 & [0.705766, 0.508363] \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×2 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m pos                               \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Array…                            \u001b[0m\n",
       "──────────┼─────────────────────────────────────────────\n",
       "        1 │        1  [0.646691, 0.112486, 0.276021]\n",
       "        2 │        2  [0.651664, 0.0566425, 0.842714]\n",
       "        3 │        3  [0.950498, 0.96467]\n",
       "        4 │        4  [0.945775, 0.789904]\n",
       "        5 │        5  [0.82116, 0.0341601, 0.0945445, …\n",
       "        6 │        6  [0.12781, 0.374187, 0.931115]\n",
       "        7 │        7  [0.438939, 0.246862, 0.0118196, …\n",
       "        8 │        8  [0.732, 0.299058]\n",
       "        9 │        9  [0.449182, 0.875096]\n",
       "       10 │       10  [0.0462887, 0.698356, 0.365109]\n",
       "       11 │       11  [0.302478, 0.372575, 0.150508, 0…\n",
       "    ⋮     │    ⋮                      ⋮\n",
       "  9999991 │  9999991  [0.700468, 0.220524, 0.347931]\n",
       "  9999992 │  9999992  [0.231368, 0.862016]\n",
       "  9999993 │  9999993  [0.869351, 0.444795]\n",
       "  9999994 │  9999994  [0.821356, 0.509054]\n",
       "  9999995 │  9999995  [0.589245, 0.669708]\n",
       "  9999996 │  9999996  [0.806262, 0.734397]\n",
       "  9999997 │  9999997  [0.216506, 0.430571, 0.283787, 0…\n",
       "  9999998 │  9999998  [0.0100723, 0.836315, 0.942299]\n",
       "  9999999 │  9999999  [0.499669, 0.25214, 0.964065]\n",
       " 10000000 │ 10000000  [0.663339, 0.887989]\n",
       "\u001b[36m                                    9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us count the number of jumps we have made in each step using the `transform!` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>10,000,000 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>pos</th><th>jumps</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Vector{Float64}\">Array…</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>[0.646691, 0.112486, 0.276021]</td><td>3</td></tr><tr><th>2</th><td>2</td><td>[0.651664, 0.0566425, 0.842714]</td><td>3</td></tr><tr><th>3</th><td>3</td><td>[0.950498, 0.96467]</td><td>2</td></tr><tr><th>4</th><td>4</td><td>[0.945775, 0.789904]</td><td>2</td></tr><tr><th>5</th><td>5</td><td>[0.82116, 0.0341601, 0.0945445, 0.314926]</td><td>4</td></tr><tr><th>6</th><td>6</td><td>[0.12781, 0.374187, 0.931115]</td><td>3</td></tr><tr><th>7</th><td>7</td><td>[0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169]</td><td>5</td></tr><tr><th>8</th><td>8</td><td>[0.732, 0.299058]</td><td>2</td></tr><tr><th>9</th><td>9</td><td>[0.449182, 0.875096]</td><td>2</td></tr><tr><th>10</th><td>10</td><td>[0.0462887, 0.698356, 0.365109]</td><td>3</td></tr><tr><th>11</th><td>11</td><td>[0.302478, 0.372575, 0.150508, 0.147329, 0.283401]</td><td>5</td></tr><tr><th>12</th><td>12</td><td>[0.404953, 0.499531, 0.658815]</td><td>3</td></tr><tr><th>13</th><td>13</td><td>[0.515627, 0.260715, 0.59552]</td><td>3</td></tr><tr><th>14</th><td>14</td><td>[0.292462, 0.28858, 0.61816]</td><td>3</td></tr><tr><th>15</th><td>15</td><td>[0.66426, 0.753508]</td><td>2</td></tr><tr><th>16</th><td>16</td><td>[0.0368842, 0.643704, 0.401421]</td><td>3</td></tr><tr><th>17</th><td>17</td><td>[0.525057, 0.61201]</td><td>2</td></tr><tr><th>18</th><td>18</td><td>[0.432577, 0.082207, 0.199058, 0.576082]</td><td>4</td></tr><tr><th>19</th><td>19</td><td>[0.218177, 0.362036, 0.204728, 0.932984]</td><td>4</td></tr><tr><th>20</th><td>20</td><td>[0.827263, 0.0992992, 0.6343]</td><td>3</td></tr><tr><th>21</th><td>21</td><td>[0.132715, 0.775194, 0.869237]</td><td>3</td></tr><tr><th>22</th><td>22</td><td>[0.0396356, 0.79041, 0.431188]</td><td>3</td></tr><tr><th>23</th><td>23</td><td>[0.137658, 0.60808, 0.255054]</td><td>3</td></tr><tr><th>24</th><td>24</td><td>[0.498734, 0.0940369, 0.52509]</td><td>3</td></tr><tr><th>25</th><td>25</td><td>[0.265511, 0.110096, 0.834362]</td><td>3</td></tr><tr><th>26</th><td>26</td><td>[0.633427, 0.337865, 0.112987]</td><td>3</td></tr><tr><th>27</th><td>27</td><td>[0.78299, 0.838042]</td><td>2</td></tr><tr><th>28</th><td>28</td><td>[0.0878598, 0.386568, 0.330579, 0.748041]</td><td>4</td></tr><tr><th>29</th><td>29</td><td>[0.265595, 0.291069, 0.612628]</td><td>3</td></tr><tr><th>30</th><td>30</td><td>[0.705766, 0.508363]</td><td>2</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& id & pos & jumps\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Array… & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & [0.646691, 0.112486, 0.276021] & 3 \\\\\n",
       "\t2 & 2 & [0.651664, 0.0566425, 0.842714] & 3 \\\\\n",
       "\t3 & 3 & [0.950498, 0.96467] & 2 \\\\\n",
       "\t4 & 4 & [0.945775, 0.789904] & 2 \\\\\n",
       "\t5 & 5 & [0.82116, 0.0341601, 0.0945445, 0.314926] & 4 \\\\\n",
       "\t6 & 6 & [0.12781, 0.374187, 0.931115] & 3 \\\\\n",
       "\t7 & 7 & [0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169] & 5 \\\\\n",
       "\t8 & 8 & [0.732, 0.299058] & 2 \\\\\n",
       "\t9 & 9 & [0.449182, 0.875096] & 2 \\\\\n",
       "\t10 & 10 & [0.0462887, 0.698356, 0.365109] & 3 \\\\\n",
       "\t11 & 11 & [0.302478, 0.372575, 0.150508, 0.147329, 0.283401] & 5 \\\\\n",
       "\t12 & 12 & [0.404953, 0.499531, 0.658815] & 3 \\\\\n",
       "\t13 & 13 & [0.515627, 0.260715, 0.59552] & 3 \\\\\n",
       "\t14 & 14 & [0.292462, 0.28858, 0.61816] & 3 \\\\\n",
       "\t15 & 15 & [0.66426, 0.753508] & 2 \\\\\n",
       "\t16 & 16 & [0.0368842, 0.643704, 0.401421] & 3 \\\\\n",
       "\t17 & 17 & [0.525057, 0.61201] & 2 \\\\\n",
       "\t18 & 18 & [0.432577, 0.082207, 0.199058, 0.576082] & 4 \\\\\n",
       "\t19 & 19 & [0.218177, 0.362036, 0.204728, 0.932984] & 4 \\\\\n",
       "\t20 & 20 & [0.827263, 0.0992992, 0.6343] & 3 \\\\\n",
       "\t21 & 21 & [0.132715, 0.775194, 0.869237] & 3 \\\\\n",
       "\t22 & 22 & [0.0396356, 0.79041, 0.431188] & 3 \\\\\n",
       "\t23 & 23 & [0.137658, 0.60808, 0.255054] & 3 \\\\\n",
       "\t24 & 24 & [0.498734, 0.0940369, 0.52509] & 3 \\\\\n",
       "\t25 & 25 & [0.265511, 0.110096, 0.834362] & 3 \\\\\n",
       "\t26 & 26 & [0.633427, 0.337865, 0.112987] & 3 \\\\\n",
       "\t27 & 27 & [0.78299, 0.838042] & 2 \\\\\n",
       "\t28 & 28 & [0.0878598, 0.386568, 0.330579, 0.748041] & 4 \\\\\n",
       "\t29 & 29 & [0.265595, 0.291069, 0.612628] & 3 \\\\\n",
       "\t30 & 30 & [0.705766, 0.508363] & 2 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×3 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m pos                               \u001b[0m\u001b[1m jumps \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Array…                            \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────────┼────────────────────────────────────────────────────\n",
       "        1 │        1  [0.646691, 0.112486, 0.276021]         3\n",
       "        2 │        2  [0.651664, 0.0566425, 0.842714]        3\n",
       "        3 │        3  [0.950498, 0.96467]                    2\n",
       "        4 │        4  [0.945775, 0.789904]                   2\n",
       "        5 │        5  [0.82116, 0.0341601, 0.0945445, …      4\n",
       "        6 │        6  [0.12781, 0.374187, 0.931115]          3\n",
       "        7 │        7  [0.438939, 0.246862, 0.0118196, …      5\n",
       "        8 │        8  [0.732, 0.299058]                      2\n",
       "        9 │        9  [0.449182, 0.875096]                   2\n",
       "       10 │       10  [0.0462887, 0.698356, 0.365109]        3\n",
       "       11 │       11  [0.302478, 0.372575, 0.150508, 0…      5\n",
       "    ⋮     │    ⋮                      ⋮                    ⋮\n",
       "  9999991 │  9999991  [0.700468, 0.220524, 0.347931]         3\n",
       "  9999992 │  9999992  [0.231368, 0.862016]                   2\n",
       "  9999993 │  9999993  [0.869351, 0.444795]                   2\n",
       "  9999994 │  9999994  [0.821356, 0.509054]                   2\n",
       "  9999995 │  9999995  [0.589245, 0.669708]                   2\n",
       "  9999996 │  9999996  [0.806262, 0.734397]                   2\n",
       "  9999997 │  9999997  [0.216506, 0.430571, 0.283787, 0…      4\n",
       "  9999998 │  9999998  [0.0100723, 0.836315, 0.942299]        3\n",
       "  9999999 │  9999999  [0.499669, 0.25214, 0.964065]          3\n",
       " 10000000 │ 10000000  [0.663339, 0.887989]                   2\n",
       "\u001b[36m                                           9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform!(df, :pos => ByRow(length) => :jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us dissect what we have written above:\n",
    "* `transform!` adds columns to a data frame in-place\n",
    "* `:pos` is a source column\n",
    "* `ByRow(length)` tells us that we want to apply `length` function to each element for `:pos` column (without it `length` would be applied to the whole column - can you guess what would be the result?)\n",
    "* `:jumps` is the name of the column that should be created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to find the average number of jumps that are made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7185991"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(df.jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>jumps_mean</th></tr><tr><th></th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>2.7186</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& jumps\\_mean\\\\\n",
       "\t\\hline\n",
       "\t& Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.7186 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1×1 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m jumps_mean \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64    \u001b[0m\n",
       "─────┼────────────\n",
       "   1 │     2.7186"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine(df, :jumps => mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which happens to be very close to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ℯ = 2.7182818284590..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MathConstants.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now find a distribution of number of jumps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>10 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>jumps</th><th>jumps_length</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>2</td><td>4999743</td></tr><tr><th>2</th><td>3</td><td>3332539</td></tr><tr><th>3</th><td>4</td><td>1250009</td></tr><tr><th>4</th><td>5</td><td>333738</td></tr><tr><th>5</th><td>6</td><td>69865</td></tr><tr><th>6</th><td>7</td><td>12145</td></tr><tr><th>7</th><td>8</td><td>1725</td></tr><tr><th>8</th><td>9</td><td>204</td></tr><tr><th>9</th><td>10</td><td>31</td></tr><tr><th>10</th><td>11</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& jumps & jumps\\_length\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2 & 4999743 \\\\\n",
       "\t2 & 3 & 3332539 \\\\\n",
       "\t3 & 4 & 1250009 \\\\\n",
       "\t4 & 5 & 333738 \\\\\n",
       "\t5 & 6 & 69865 \\\\\n",
       "\t6 & 7 & 12145 \\\\\n",
       "\t7 & 8 & 1725 \\\\\n",
       "\t8 & 9 & 204 \\\\\n",
       "\t9 & 10 & 31 \\\\\n",
       "\t10 & 11 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m jumps \u001b[0m\u001b[1m jumps_length \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64        \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │     2       4999743\n",
       "   2 │     3       3332539\n",
       "   3 │     4       1250009\n",
       "   4 │     5        333738\n",
       "   5 │     6         69865\n",
       "   6 │     7         12145\n",
       "   7 │     8          1725\n",
       "   8 │     9           204\n",
       "   9 │    10            31\n",
       "  10 │    11             1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumps_agg = @pipe df |>\n",
    "                  groupby(_, :jumps, sort=true) |>\n",
    "                  combine(_, :jumps => length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and normalize it as a fraction (and at the same time calculate some theoretical result that we have *guessed* :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>10 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>jumps</th><th>jumps_length</th><th>simulation</th><th>theory</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>2</td><td>4999743</td><td>0.499974</td><td>0.5</td></tr><tr><th>2</th><td>3</td><td>3332539</td><td>0.333254</td><td>0.333333</td></tr><tr><th>3</th><td>4</td><td>1250009</td><td>0.125001</td><td>0.125</td></tr><tr><th>4</th><td>5</td><td>333738</td><td>0.0333738</td><td>0.0333333</td></tr><tr><th>5</th><td>6</td><td>69865</td><td>0.0069865</td><td>0.00694444</td></tr><tr><th>6</th><td>7</td><td>12145</td><td>0.0012145</td><td>0.00119048</td></tr><tr><th>7</th><td>8</td><td>1725</td><td>0.0001725</td><td>0.000173611</td></tr><tr><th>8</th><td>9</td><td>204</td><td>2.04e-5</td><td>2.20459e-5</td></tr><tr><th>9</th><td>10</td><td>31</td><td>3.1e-6</td><td>2.48016e-6</td></tr><tr><th>10</th><td>11</td><td>1</td><td>1.0e-7</td><td>2.50521e-7</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& jumps & jumps\\_length & simulation & theory\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2 & 4999743 & 0.499974 & 0.5 \\\\\n",
       "\t2 & 3 & 3332539 & 0.333254 & 0.333333 \\\\\n",
       "\t3 & 4 & 1250009 & 0.125001 & 0.125 \\\\\n",
       "\t4 & 5 & 333738 & 0.0333738 & 0.0333333 \\\\\n",
       "\t5 & 6 & 69865 & 0.0069865 & 0.00694444 \\\\\n",
       "\t6 & 7 & 12145 & 0.0012145 & 0.00119048 \\\\\n",
       "\t7 & 8 & 1725 & 0.0001725 & 0.000173611 \\\\\n",
       "\t8 & 9 & 204 & 2.04e-5 & 2.20459e-5 \\\\\n",
       "\t9 & 10 & 31 & 3.1e-6 & 2.48016e-6 \\\\\n",
       "\t10 & 11 & 1 & 1.0e-7 & 2.50521e-7 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m jumps \u001b[0m\u001b[1m jumps_length \u001b[0m\u001b[1m simulation \u001b[0m\u001b[1m theory      \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64        \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼──────────────────────────────────────────────\n",
       "   1 │     2       4999743   0.499974   0.5\n",
       "   2 │     3       3332539   0.333254   0.333333\n",
       "   3 │     4       1250009   0.125001   0.125\n",
       "   4 │     5        333738   0.0333738  0.0333333\n",
       "   5 │     6         69865   0.0069865  0.00694444\n",
       "   6 │     7         12145   0.0012145  0.00119048\n",
       "   7 │     8          1725   0.0001725  0.000173611\n",
       "   8 │     9           204   2.04e-5    2.20459e-5\n",
       "   9 │    10            31   3.1e-6     2.48016e-6\n",
       "  10 │    11             1   1.0e-7     2.50521e-7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform!(jumps_agg,\n",
    "           :jumps_length => (x -> x ./ sum(x)) => :simulation,\n",
    "           :jumps => ByRow(x -> (x-1) / factorial(x)) => :theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly justify how we have guessed it (you can safely skip the derivation):\n",
    "\n",
    "Formula\n",
    "$$\n",
    "p_n = \\frac{n-1}{n!}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{n=2}^{+\\infty}p_n=\\sum_{n=2}^{+\\infty} \\frac{n-1}{n!} = \\sum_{n=1}^{+\\infty} \\frac{1}{n!} - \\sum_{n=2}^{+\\infty} \\frac{1}{n!} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{n=2}^{+\\infty}n\\cdot p_n=\\sum_{n=2}^{+\\infty} n\\frac{n-1}{n!} = \\sum_{n=2}^{+\\infty} \\frac{1}{(n-2)!} = e\n",
    "$$\n",
    "\n",
    "Now we note that:\n",
    "\n",
    "$$\n",
    "1-\\sum_{n=2}^k p_n = \\frac{1}{k!}\n",
    "$$\n",
    "which can be most easily justified by a geometric argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish this section of the tutorial let us check if random numbers generated using `rand()` were indeed $U(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we will add some columns to `df` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>10,000,000 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>pos</th><th>jumps</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Vector{Float64}\">Array…</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>[0.646691, 0.112486, 0.276021]</td><td>3</td></tr><tr><th>2</th><td>2</td><td>[0.651664, 0.0566425, 0.842714]</td><td>3</td></tr><tr><th>3</th><td>3</td><td>[0.950498, 0.96467]</td><td>2</td></tr><tr><th>4</th><td>4</td><td>[0.945775, 0.789904]</td><td>2</td></tr><tr><th>5</th><td>5</td><td>[0.82116, 0.0341601, 0.0945445, 0.314926]</td><td>4</td></tr><tr><th>6</th><td>6</td><td>[0.12781, 0.374187, 0.931115]</td><td>3</td></tr><tr><th>7</th><td>7</td><td>[0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169]</td><td>5</td></tr><tr><th>8</th><td>8</td><td>[0.732, 0.299058]</td><td>2</td></tr><tr><th>9</th><td>9</td><td>[0.449182, 0.875096]</td><td>2</td></tr><tr><th>10</th><td>10</td><td>[0.0462887, 0.698356, 0.365109]</td><td>3</td></tr><tr><th>11</th><td>11</td><td>[0.302478, 0.372575, 0.150508, 0.147329, 0.283401]</td><td>5</td></tr><tr><th>12</th><td>12</td><td>[0.404953, 0.499531, 0.658815]</td><td>3</td></tr><tr><th>13</th><td>13</td><td>[0.515627, 0.260715, 0.59552]</td><td>3</td></tr><tr><th>14</th><td>14</td><td>[0.292462, 0.28858, 0.61816]</td><td>3</td></tr><tr><th>15</th><td>15</td><td>[0.66426, 0.753508]</td><td>2</td></tr><tr><th>16</th><td>16</td><td>[0.0368842, 0.643704, 0.401421]</td><td>3</td></tr><tr><th>17</th><td>17</td><td>[0.525057, 0.61201]</td><td>2</td></tr><tr><th>18</th><td>18</td><td>[0.432577, 0.082207, 0.199058, 0.576082]</td><td>4</td></tr><tr><th>19</th><td>19</td><td>[0.218177, 0.362036, 0.204728, 0.932984]</td><td>4</td></tr><tr><th>20</th><td>20</td><td>[0.827263, 0.0992992, 0.6343]</td><td>3</td></tr><tr><th>21</th><td>21</td><td>[0.132715, 0.775194, 0.869237]</td><td>3</td></tr><tr><th>22</th><td>22</td><td>[0.0396356, 0.79041, 0.431188]</td><td>3</td></tr><tr><th>23</th><td>23</td><td>[0.137658, 0.60808, 0.255054]</td><td>3</td></tr><tr><th>24</th><td>24</td><td>[0.498734, 0.0940369, 0.52509]</td><td>3</td></tr><tr><th>25</th><td>25</td><td>[0.265511, 0.110096, 0.834362]</td><td>3</td></tr><tr><th>26</th><td>26</td><td>[0.633427, 0.337865, 0.112987]</td><td>3</td></tr><tr><th>27</th><td>27</td><td>[0.78299, 0.838042]</td><td>2</td></tr><tr><th>28</th><td>28</td><td>[0.0878598, 0.386568, 0.330579, 0.748041]</td><td>4</td></tr><tr><th>29</th><td>29</td><td>[0.265595, 0.291069, 0.612628]</td><td>3</td></tr><tr><th>30</th><td>30</td><td>[0.705766, 0.508363]</td><td>2</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& id & pos & jumps\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Array… & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & [0.646691, 0.112486, 0.276021] & 3 \\\\\n",
       "\t2 & 2 & [0.651664, 0.0566425, 0.842714] & 3 \\\\\n",
       "\t3 & 3 & [0.950498, 0.96467] & 2 \\\\\n",
       "\t4 & 4 & [0.945775, 0.789904] & 2 \\\\\n",
       "\t5 & 5 & [0.82116, 0.0341601, 0.0945445, 0.314926] & 4 \\\\\n",
       "\t6 & 6 & [0.12781, 0.374187, 0.931115] & 3 \\\\\n",
       "\t7 & 7 & [0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169] & 5 \\\\\n",
       "\t8 & 8 & [0.732, 0.299058] & 2 \\\\\n",
       "\t9 & 9 & [0.449182, 0.875096] & 2 \\\\\n",
       "\t10 & 10 & [0.0462887, 0.698356, 0.365109] & 3 \\\\\n",
       "\t11 & 11 & [0.302478, 0.372575, 0.150508, 0.147329, 0.283401] & 5 \\\\\n",
       "\t12 & 12 & [0.404953, 0.499531, 0.658815] & 3 \\\\\n",
       "\t13 & 13 & [0.515627, 0.260715, 0.59552] & 3 \\\\\n",
       "\t14 & 14 & [0.292462, 0.28858, 0.61816] & 3 \\\\\n",
       "\t15 & 15 & [0.66426, 0.753508] & 2 \\\\\n",
       "\t16 & 16 & [0.0368842, 0.643704, 0.401421] & 3 \\\\\n",
       "\t17 & 17 & [0.525057, 0.61201] & 2 \\\\\n",
       "\t18 & 18 & [0.432577, 0.082207, 0.199058, 0.576082] & 4 \\\\\n",
       "\t19 & 19 & [0.218177, 0.362036, 0.204728, 0.932984] & 4 \\\\\n",
       "\t20 & 20 & [0.827263, 0.0992992, 0.6343] & 3 \\\\\n",
       "\t21 & 21 & [0.132715, 0.775194, 0.869237] & 3 \\\\\n",
       "\t22 & 22 & [0.0396356, 0.79041, 0.431188] & 3 \\\\\n",
       "\t23 & 23 & [0.137658, 0.60808, 0.255054] & 3 \\\\\n",
       "\t24 & 24 & [0.498734, 0.0940369, 0.52509] & 3 \\\\\n",
       "\t25 & 25 & [0.265511, 0.110096, 0.834362] & 3 \\\\\n",
       "\t26 & 26 & [0.633427, 0.337865, 0.112987] & 3 \\\\\n",
       "\t27 & 27 & [0.78299, 0.838042] & 2 \\\\\n",
       "\t28 & 28 & [0.0878598, 0.386568, 0.330579, 0.748041] & 4 \\\\\n",
       "\t29 & 29 & [0.265595, 0.291069, 0.612628] & 3 \\\\\n",
       "\t30 & 30 & [0.705766, 0.508363] & 2 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×3 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m pos                               \u001b[0m\u001b[1m jumps \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Array…                            \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────────┼────────────────────────────────────────────────────\n",
       "        1 │        1  [0.646691, 0.112486, 0.276021]         3\n",
       "        2 │        2  [0.651664, 0.0566425, 0.842714]        3\n",
       "        3 │        3  [0.950498, 0.96467]                    2\n",
       "        4 │        4  [0.945775, 0.789904]                   2\n",
       "        5 │        5  [0.82116, 0.0341601, 0.0945445, …      4\n",
       "        6 │        6  [0.12781, 0.374187, 0.931115]          3\n",
       "        7 │        7  [0.438939, 0.246862, 0.0118196, …      5\n",
       "        8 │        8  [0.732, 0.299058]                      2\n",
       "        9 │        9  [0.449182, 0.875096]                   2\n",
       "       10 │       10  [0.0462887, 0.698356, 0.365109]        3\n",
       "       11 │       11  [0.302478, 0.372575, 0.150508, 0…      5\n",
       "    ⋮     │    ⋮                      ⋮                    ⋮\n",
       "  9999991 │  9999991  [0.700468, 0.220524, 0.347931]         3\n",
       "  9999992 │  9999992  [0.231368, 0.862016]                   2\n",
       "  9999993 │  9999993  [0.869351, 0.444795]                   2\n",
       "  9999994 │  9999994  [0.821356, 0.509054]                   2\n",
       "  9999995 │  9999995  [0.589245, 0.669708]                   2\n",
       "  9999996 │  9999996  [0.806262, 0.734397]                   2\n",
       "  9999997 │  9999997  [0.216506, 0.430571, 0.283787, 0…      4\n",
       "  9999998 │  9999998  [0.0100723, 0.836315, 0.942299]        3\n",
       "  9999999 │  9999999  [0.499669, 0.25214, 0.964065]          3\n",
       " 10000000 │ 10000000  [0.663339, 0.887989]                   2\n",
       "\u001b[36m                                           9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>10,000,000 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>first</th><th>last</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.646691</td><td>0.276021</td></tr><tr><th>2</th><td>0.651664</td><td>0.842714</td></tr><tr><th>3</th><td>0.950498</td><td>0.96467</td></tr><tr><th>4</th><td>0.945775</td><td>0.789904</td></tr><tr><th>5</th><td>0.82116</td><td>0.314926</td></tr><tr><th>6</th><td>0.12781</td><td>0.931115</td></tr><tr><th>7</th><td>0.438939</td><td>0.496169</td></tr><tr><th>8</th><td>0.732</td><td>0.299058</td></tr><tr><th>9</th><td>0.449182</td><td>0.875096</td></tr><tr><th>10</th><td>0.0462887</td><td>0.365109</td></tr><tr><th>11</th><td>0.302478</td><td>0.283401</td></tr><tr><th>12</th><td>0.404953</td><td>0.658815</td></tr><tr><th>13</th><td>0.515627</td><td>0.59552</td></tr><tr><th>14</th><td>0.292462</td><td>0.61816</td></tr><tr><th>15</th><td>0.66426</td><td>0.753508</td></tr><tr><th>16</th><td>0.0368842</td><td>0.401421</td></tr><tr><th>17</th><td>0.525057</td><td>0.61201</td></tr><tr><th>18</th><td>0.432577</td><td>0.576082</td></tr><tr><th>19</th><td>0.218177</td><td>0.932984</td></tr><tr><th>20</th><td>0.827263</td><td>0.6343</td></tr><tr><th>21</th><td>0.132715</td><td>0.869237</td></tr><tr><th>22</th><td>0.0396356</td><td>0.431188</td></tr><tr><th>23</th><td>0.137658</td><td>0.255054</td></tr><tr><th>24</th><td>0.498734</td><td>0.52509</td></tr><tr><th>25</th><td>0.265511</td><td>0.834362</td></tr><tr><th>26</th><td>0.633427</td><td>0.112987</td></tr><tr><th>27</th><td>0.78299</td><td>0.838042</td></tr><tr><th>28</th><td>0.0878598</td><td>0.748041</td></tr><tr><th>29</th><td>0.265595</td><td>0.612628</td></tr><tr><th>30</th><td>0.705766</td><td>0.508363</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& first & last\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.646691 & 0.276021 \\\\\n",
       "\t2 & 0.651664 & 0.842714 \\\\\n",
       "\t3 & 0.950498 & 0.96467 \\\\\n",
       "\t4 & 0.945775 & 0.789904 \\\\\n",
       "\t5 & 0.82116 & 0.314926 \\\\\n",
       "\t6 & 0.12781 & 0.931115 \\\\\n",
       "\t7 & 0.438939 & 0.496169 \\\\\n",
       "\t8 & 0.732 & 0.299058 \\\\\n",
       "\t9 & 0.449182 & 0.875096 \\\\\n",
       "\t10 & 0.0462887 & 0.365109 \\\\\n",
       "\t11 & 0.302478 & 0.283401 \\\\\n",
       "\t12 & 0.404953 & 0.658815 \\\\\n",
       "\t13 & 0.515627 & 0.59552 \\\\\n",
       "\t14 & 0.292462 & 0.61816 \\\\\n",
       "\t15 & 0.66426 & 0.753508 \\\\\n",
       "\t16 & 0.0368842 & 0.401421 \\\\\n",
       "\t17 & 0.525057 & 0.61201 \\\\\n",
       "\t18 & 0.432577 & 0.576082 \\\\\n",
       "\t19 & 0.218177 & 0.932984 \\\\\n",
       "\t20 & 0.827263 & 0.6343 \\\\\n",
       "\t21 & 0.132715 & 0.869237 \\\\\n",
       "\t22 & 0.0396356 & 0.431188 \\\\\n",
       "\t23 & 0.137658 & 0.255054 \\\\\n",
       "\t24 & 0.498734 & 0.52509 \\\\\n",
       "\t25 & 0.265511 & 0.834362 \\\\\n",
       "\t26 & 0.633427 & 0.112987 \\\\\n",
       "\t27 & 0.78299 & 0.838042 \\\\\n",
       "\t28 & 0.0878598 & 0.748041 \\\\\n",
       "\t29 & 0.265595 & 0.612628 \\\\\n",
       "\t30 & 0.705766 & 0.508363 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×2 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m first     \u001b[0m\u001b[1m last     \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "──────────┼─────────────────────\n",
       "        1 │ 0.646691   0.276021\n",
       "        2 │ 0.651664   0.842714\n",
       "        3 │ 0.950498   0.96467\n",
       "        4 │ 0.945775   0.789904\n",
       "        5 │ 0.82116    0.314926\n",
       "        6 │ 0.12781    0.931115\n",
       "        7 │ 0.438939   0.496169\n",
       "        8 │ 0.732      0.299058\n",
       "        9 │ 0.449182   0.875096\n",
       "       10 │ 0.0462887  0.365109\n",
       "       11 │ 0.302478   0.283401\n",
       "    ⋮     │     ⋮         ⋮\n",
       "  9999991 │ 0.700468   0.347931\n",
       "  9999992 │ 0.231368   0.862016\n",
       "  9999993 │ 0.869351   0.444795\n",
       "  9999994 │ 0.821356   0.509054\n",
       "  9999995 │ 0.589245   0.669708\n",
       "  9999996 │ 0.806262   0.734397\n",
       "  9999997 │ 0.216506   0.335015\n",
       "  9999998 │ 0.0100723  0.942299\n",
       "  9999999 │ 0.499669   0.964065\n",
       " 10000000 │ 0.663339   0.887989\n",
       "\u001b[36m            9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = select(df, :pos => ByRow(first) => :first, :pos => ByRow(last) => :last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(df_test.first, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far all looks good. But let us look at the distribution of the last dawn random number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(df_test.last, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So - is the `rand()` function broken for the last generated random number in each sequence or something else has made the distribution stop being uniform?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
