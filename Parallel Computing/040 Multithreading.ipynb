{
 "cells": [
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Pkg; Pkg.add(Pkg.PackageSpec(url=\"https://github.com/JuliaComputing/JuliaAcademyData.jl\"))\n",
    "using JuliaAcademyData; activate(\"Parallel_Computing\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Multithreading\n",
    "\n",
    "Now we're finally ready to start talking about running things on multiple\n",
    "processors! Most computers (even cell phones) these days have multiple cores\n",
    "or processors — so the obvious place to start working with parallelism is\n",
    "making use of those from within our Julia process.\n",
    "\n",
    "The first challenge, though, is knowing precisely how many \"processors\" you have.\n",
    "\"Processors\" is in scare quotes because, well, it's complicated."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "versioninfo(verbose = true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    ";cat /proc/cpuinfo # on Linux machines\n",
    "\n",
    "using Hwloc\n",
    "Hwloc.num_physical_cores()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "What your computer reports as the number of processors might not be the same\n",
    "as the total number of \"cores\". While sometimes virtual processors can add\n",
    "performance, parallelizing a typical numerical computation over these virtual\n",
    "processors will lead to significantly worse performance because they still\n",
    "have to share much of the nuts and bolts of the computation hardware."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Julia is somewhat multithreaded by default! BLAS calls (like matrix multiplication) are\n",
    "already threaded:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools\n",
    "A = rand(2000, 2000);\n",
    "B = rand(2000, 2000);\n",
    "@btime $A*$B;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "This is — by default — already using all your CPU cores! You can see the effect\n",
    "by changing the number of threads (which BLAS supports doing dynamically):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using LinearAlgebra\n",
    "BLAS.set_num_threads(1)\n",
    "@btime $A*$B\n",
    "BLAS.set_num_threads(4)\n",
    "@btime $A*$B"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## What does it look like to implement your _own_ threaded algorithm?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Multithreading support is marked as \"experimental\" for Julia 1.0 and is\n",
    "pending a big revamp for Julia version 1.2 or 1.3. The core tenets will be\n",
    "the same, but it should become much easier to use efficiently."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using .Threads\n",
    "\n",
    "nthreads()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Julia currently needs to start up knowing that it has threading support enabled.\n",
    "\n",
    "You do that with a environment variable. To get four threads, start Julia with:\n",
    "\n",
    "```\n",
    "JULIA_NUM_THREADS=4 julia\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "On JuliaBox, this is a challenge — we don't have access to the launching process!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    ";env JULIA_NUM_THREADS=4 julia -E 'using .Threads; nthreads()'"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "threadid()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So we're currently on thread 1. Of course a loop like this will\n",
    "just set the first element to one a number of times:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = Array{Union{Int,Missing}}(missing, nthreads())\n",
    "for i in 1:nthreads()\n",
    "    A[threadid()] = threadid()\n",
    "end\n",
    "A"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "But if we prefix it with `@threads` then the loop body runs on all threads!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@threads for i in 1:nthreads()\n",
    "    A[threadid()] = threadid()\n",
    "end\n",
    "A"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So let's try implementing our first simple threaded algorithm — `sum`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function threaded_sum1(A)\n",
    "    r = zero(eltype(A))\n",
    "    @threads for i in eachindex(A)\n",
    "        @inbounds r += A[i]\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "A = rand(10_000_000)\n",
    "threaded_sum1(A)\n",
    "@time threaded_sum1(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sum(A)\n",
    "@time sum(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Whoa! What happened? Not only did we get the wrong answer, it was _slow_ to get it!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function threaded_sum2(A)\n",
    "    r = Atomic{eltype(A)}(zero(eltype(A)))\n",
    "    @threads for i in eachindex(A)\n",
    "        @inbounds atomic_add!(r, A[i])\n",
    "    end\n",
    "    return r[]\n",
    "end\n",
    "\n",
    "threaded_sum2(A)\n",
    "@time threaded_sum2(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Alright! Now we got the correct answer (modulo some floating point associativity),\n",
    "but it's still slower than just doing the simple thing on 1 core."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "threaded_sum2(A) ≈ sum(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "But it's still slow! Using atomics is much slower than just adding integers\n",
    "because we constantly have to go and check _which_ processor has the latest\n",
    "work! Also remember that each thread is running on its own processor — and\n",
    "that processor also supports SIMD!  Well, that is if it didn't need to worry\n",
    "about syncing up with the other processors..."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function threaded_sum3(A)\n",
    "    r = Atomic{eltype(A)}(zero(eltype(A)))\n",
    "    len, rem = divrem(length(A), nthreads())\n",
    "    @threads for t in 1:nthreads()\n",
    "        rₜ = zero(eltype(A))\n",
    "        @simd for i in (1:len) .+ (t-1)*len\n",
    "            @inbounds rₜ += A[i]\n",
    "        end\n",
    "        atomic_add!(r, rₜ)\n",
    "    end\n",
    "    # catch up any stragglers\n",
    "    result = r[]\n",
    "    @simd for i in length(A)-rem+1:length(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "threaded_sum3(A)\n",
    "@time threaded_sum3(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Dang, that's complicated. There's also a problem:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "threaded_sum3(rand(10) .+ rand(10)im) # try an array of complex numbers!"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Isn't there an easier way?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "R = zeros(eltype(A), nthreads())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function threaded_sum4(A)\n",
    "    R = zeros(eltype(A), nthreads())\n",
    "    @threads for i in eachindex(A)\n",
    "        @inbounds R[threadid()] += A[i]\n",
    "    end\n",
    "    r = zero(eltype(A))\n",
    "    # sum the partial results from each thread\n",
    "    for i in eachindex(R)\n",
    "        @inbounds r += R[i]\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "threaded_sum4(A)\n",
    "@time threaded_sum4(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "This sacrifices our ability to `@simd` so it's a little slower, but at least we don't need to worry\n",
    "about all those indices! And we also don't need to worry about atomics and\n",
    "can again support arrays of any elements:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "threaded_sum4(rand(10) .+ rand(10)im)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Key takeaways from `threaded_sum`:\n",
    "\n",
    "* Beware shared state across threads — it may lead to wrong answers!\n",
    "    * Protect yourself by using atomics (or [locks/mutexes](https://docs.julialang.org/en/v1/base/multi-threading/#Synchronization-Primitives-1))\n",
    "    * Better yet: divide up the work manually such that the inner loops don't\n",
    "      share state. `@threads for i in 1:nthreads()` is a handy idiom.\n",
    "    * Alternatively, just use an array and only access a single thread's elements"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Beware of global state (even if it's not obvious!)\n",
    "\n",
    "Another class of algorithm that you may want to parallelize is a monte-carlo\n",
    "problem. Since each iteration is a new random draw, and since you're interested\n",
    "in looking at the aggregate result, this seems like it should lend itself to\n",
    "parallelism quite nicely!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function serialpi(n)\n",
    "    inside = 0\n",
    "    for i in 1:n\n",
    "        x, y = rand(), rand()\n",
    "        inside += (x^2 + y^2 <= 1)\n",
    "    end\n",
    "    return 4 * inside / n\n",
    "end\n",
    "serialpi(1)\n",
    "@time serialpi(100_000_000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using .Threads\n",
    "nthreads()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's use the techniques we learned above to make a fast threaded implementation:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function threadedpi(n)\n",
    "    inside = zeros(Int, nthreads())\n",
    "    @threads for i in 1:n\n",
    "        x, y = rand(), rand()\n",
    "        @inbounds inside[threadid()] += (x^2 + y^2 <= 1)\n",
    "    end\n",
    "    return 4 * sum(inside) / n\n",
    "end\n",
    "threadedpi(100_000_000)\n",
    "@time threadedpi(100_000_000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Ok, now why didn't that work?  It's slow! Let's look at the sequence of random\n",
    "numbers that we generate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Random\n",
    "Random.seed!(0)\n",
    "N = 20000\n",
    "Rserial = zeros(N)\n",
    "for i in 1:N\n",
    "    Rserial[i] = rand()\n",
    "end\n",
    "Rserial"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(0)\n",
    "Rthreaded = zeros(N)\n",
    "@threads for i in 1:N\n",
    "    Rthreaded[i] = rand()\n",
    "end\n",
    "Rthreaded"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Set(Rserial) == Set(Rthreaded)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "indexin(Rserial, Rthreaded)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Aha, `rand()` isn't threadsafe! It's mutating (and reading) some global each\n",
    "time to figure out what to get next. This leads to slowdowns — and worse — it\n",
    "skews the generated distribution of random numbers since some are repeated!!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "const ThreadRNG = Vector{Random.MersenneTwister}(undef, nthreads())\n",
    "@threads for i in 1:nthreads()\n",
    "    ThreadRNG[Threads.threadid()] = Random.MersenneTwister()\n",
    "end\n",
    "function threadedpi2(n)\n",
    "    inside = zeros(Int, nthreads())\n",
    "    len, rem = divrem(n, nthreads())\n",
    "    rem == 0 || error(\"use a multiple of $(nthreads()), please!\")\n",
    "    @threads for i in 1:nthreads()\n",
    "        rng = ThreadRNG[threadid()]\n",
    "        v = 0\n",
    "        for j in 1:len\n",
    "            x, y = rand(rng), rand(rng)\n",
    "            v += (x^2 + y^2 <= 1)\n",
    "        end\n",
    "        inside[threadid()] = v\n",
    "    end\n",
    "    return 4 * sum(inside) / n\n",
    "end\n",
    "threadedpi2(10)\n",
    "@time threadedpi2(100_000_000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As an aside, be careful about initializing many `MersenneTwister`s with\n",
    "different states. Better to use [`randjump`](https://docs.julialang.org/en/v1/manual/parallel-computing/#Side-effects-and-mutable-function-arguments-1) to skip ahead for a single state."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Beware oversubscription\n",
    "\n",
    "Remember how BLAS is threaded by default? What happens if we try to `@threads`\n",
    "something that uses BLAS?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Ms = [rand(1000, 1000) for _ in 1:100]\n",
    "function serial_matmul(As)\n",
    "    first_idxs = zeros(length(As))\n",
    "    for i in eachindex(As)\n",
    "        @inbounds first_idxs[i] = (As[i]'*As[i])[1]\n",
    "    end\n",
    "    first_idxs\n",
    "end\n",
    "serial_matmul(Ms);\n",
    "@time serial_matmul(Ms);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using LinearAlgebra\n",
    "BLAS.set_num_threads(nthreads()) # Explicitly tell BLAS to use the same number of threads\n",
    "function threaded_matmul(As)\n",
    "    first_idxs = zeros(length(As))\n",
    "    @threads for i in eachindex(As)\n",
    "        @inbounds first_idxs[i] = (As[i]'*As[i])[1]\n",
    "    end\n",
    "    first_idxs\n",
    "end\n",
    "threaded_matmul(Ms)\n",
    "@time threaded_matmul(Ms);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "BLAS.set_num_threads(1)\n",
    "@time threaded_matmul(Ms);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@time serial_matmul(Ms) # Again, now that BLAS has just 1 thread"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Beware \"false sharing\""
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Remember the memory latency table?\n",
    "\n",
    "\n",
    "| System Event                   | Actual Latency | Scaled Latency |                          |\n",
    "| ------------------------------ | -------------- | -------------- | ------------------------ |\n",
    "| One CPU cycle                  |     0.4 ns     |     1 s        | ← work happens here     |\n",
    "| Level 1 cache access           |     0.9 ns     |     2 s        |                          |\n",
    "| Level 2 cache access           |     2.8 ns     |     7 s        |                          |\n",
    "| Level 3 cache access           |      28 ns     |     1 min      |                          |\n",
    "| Main memory access (DDR DIMM)  |    ~100 ns     |     4 min      | ← we have control here  |\n",
    "\n",
    "This is what a typical modern cpu looks like:\n",
    "\n",
    "![Intel Core i7](https://raw.githubusercontent.com/JuliaComputing/JuliaAcademyData.jl/master/courses/Parallel_Computing/images/i7.jpg)\n",
    "\n",
    "Multiple cores on the same processor share the L3 cache, but do not share L1 and L2 caches! So what happens if we're accessing and mutating data from the same array across multiple cores?\n",
    "\n",
    "![Cache coherency](https://raw.githubusercontent.com/JuliaComputing/JuliaAcademyData.jl/master/courses/Parallel_Computing/images/false-sharing.gif)\n",
    "\n",
    "Unlike \"true\" sharing — which we saw above — false sharing will still return the correct answer! But it does so at the cost of performance. The cores recognize they don't have exclusive access to the cache line and so upon modification they alert all other cores to invalidate and re-fetch the data.\n",
    "\n",
    "```julia\n",
    "function threaded_sum4(A)\n",
    "    R = zeros(eltype(A), nthreads())\n",
    "    @threads for i in eachindex(A)\n",
    "        @inbounds R[threadid()] += A[i]\n",
    "    end\n",
    "    r = zero(eltype(A))\n",
    "    # sum the partial results from each thread\n",
    "    for i in eachindex(R)\n",
    "        @inbounds r += R[i]\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Further improvements coming here!\n",
    "\n",
    "PARTR — the threading improvement I discussed at the beginning aims to address\n",
    "this problem of having library functions implemented with `@threads` and then\n",
    "having callers call them with `@threads`. Uses a state-of-the-art work queue\n",
    "mechanism to make sure that all threads stay busy."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Threading takeaways:\n",
    "\n",
    "* It's easy! Just start Julia with `JULIA_NUM_THREADS` and tack a `@threads` on your loop\n",
    "* Well, not so fast\n",
    "    * Be aware of your hardware to set `JULIA_NUM_THREADS` appropiately\n",
    "    * Beware shared state (for both performance and correctness)\n",
    "    * Beware global state (even if it's not obvious)\n",
    "    * Beware false sharing (if Julia/LLVM don't handle it for you)\n",
    "* We need to think carefully about how to design parallel algorithms!"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
