{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# SIMD: The parallelism that can (sometimes) happen automatically\n",
    "\n",
    "SIMD: Single-instruction, multiple data\n",
    "\n",
    "(Also confusingly called vectorization)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## The architecture\n",
    "\n",
    "Instead of computing four sums sequentially:\n",
    "\n",
    "\\begin{align}\n",
    "x_1 + y_1 &\\rightarrow z_1 \\\\\n",
    "x_2 + y_2 &\\rightarrow z_2 \\\\\n",
    "x_3 + y_3 &\\rightarrow z_3 \\\\\n",
    "x_4 + y_4 &\\rightarrow z_4\n",
    "\\end{align}\n",
    "\n",
    "Modern processors have vector processing units that can do it all at once:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4\n",
    "\\end{array}\\right)\n",
    "\\rightarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "z_1 \\\\\n",
    "z_2 \\\\\n",
    "z_3 \\\\\n",
    "z_4\n",
    "\\end{array}\\right)\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Making it happen"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Simple task: compute the sum of a vector:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = rand(100_000)\n",
    "function simplesum(A)\n",
    "    result = zero(eltype(A))\n",
    "    for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "simplesum(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools\n",
    "@btime simplesum($A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So, is that good?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@btime sum($A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We're slower that the builtin `sum` — and we're getting a different answer, too! Let's look at what happens with a 32-bit float instead of a 64 bit one. Each element has half the number of bits, so lets also double the length (so the total number of bits processed remains constant)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A32 = rand(Float32, length(A)*2)\n",
    "@btime simplesum($A32)\n",
    "@btime sum($A32);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "That's even worse! What's going on here?  We're seeing an even multiple number\n",
    "difference in our performance — perhaps Julia's builtin sum is using some\n",
    "parallelism? Let's try using SIMD ourselves:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function simdsum(A)\n",
    "    result = zero(eltype(A))\n",
    "    @simd for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "@btime simdsum($A)\n",
    "@btime simdsum($A32)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "What did that do and why don't we always use `@simd for` — or why doesn't Julia\n",
    "just always use `@simd` for every `for` loop automatically?  Look at the values:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "simplesum(A), simdsum(A), sum(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "simplesum(A32), simdsum(A32), sum(A32)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Why aren't they the same?\n",
    "\n",
    "Without `@simd`, Julia is doing _exactly_ what we told it to do: it's taking\n",
    "each element of our array and adding it to a big pile sequentially. Our answer\n",
    "is smaller than what Julia's builtin `sum` thinks it is: that's because as our\n",
    "pile gets bigger we begin losing the lower bits of each element that we're\n",
    "adding, and those small losses begin to add up!\n",
    "\n",
    "The `@simd` macro tells Julia that it can re-arrange floating point additions —\n",
    "even if it would change the answer. Depending on your CPU, this may lead to 2x or 4x\n",
    "or even 8x parallelism. Essentially, Julia is computing independent sums for\n",
    "the even indices and the odd indices simultaneously:\n",
    "\n",
    "\\begin{align}\n",
    "odds &\\leftarrow 0 \\\\\n",
    "evens &\\leftarrow 0 \\\\\n",
    "\\text{loop}&\\ \\text{odd}\\ i: \\\\\n",
    "    &\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "\\leftarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "x_{i} \\\\\n",
    "x_{i+1}\n",
    "\\end{array}\\right) \\\\\n",
    "total &\\leftarrow evens + odds\n",
    "\\end{align}\n",
    "\n",
    "In many cases, Julia can and does know that a for-loop can be SIMD-ed and it\n",
    "will take advantage of this by default!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "B = rand(1:10, 100_000)\n",
    "@btime simplesum($B)\n",
    "@btime sum($B)\n",
    "B32 = rand(Int32(1):Int32(10), length(B)*2)\n",
    "@btime simplesum($B32)\n",
    "@btime simdsum($B32)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "How can we see if something is getting vectorized?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@code_llvm simdsum(A32)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So what are the challenges?\n",
    "\n",
    "* Biggest hurdle is that you have to convince Julia and LLVM that it's able to\n",
    "  use SIMD instructions for your given algorithm. That's not always possible.\n",
    "* There are lots of limitations of what can and cannot be SIMD-ed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@doc @simd"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "* You do need to think through the consequences of re-ordering your algorithm."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## A slightly trickier case"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function diff!(A, B)\n",
    "    A[1] = B[1]\n",
    "    for i in 2:length(A)\n",
    "        @inbounds A[i] = B[i] - B[i-1]\n",
    "    end\n",
    "    return A\n",
    "end\n",
    "A = zeros(Float32, 100_000)\n",
    "B = rand(Float32, 100_000)\n",
    "\n",
    "diff!(A, B)\n",
    "[B[1];diff(B)] == A"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@btime diff!($A, $B)\n",
    "@btime diff($B);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "But what happens if we do it in-place?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Bcopy = copy(B)\n",
    "@btime diff!($Bcopy, $Bcopy);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "What happened?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@code_llvm diff!(A, B)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can manually assert that arrays don't alias (or have any loop-dependencies),\n",
    "with the very special `@simd ivdep` flag, but this can be disastrous:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function unsafe_diff!(A, B)\n",
    "    A[1] = B[1]\n",
    "    @simd ivdep for i in 2:length(A)\n",
    "        @inbounds A[i] = B[i] - B[i-1]\n",
    "    end\n",
    "    return A\n",
    "end\n",
    "@btime unsafe_diff!($A, $B)\n",
    "[B[1];diff(B)] == A\n",
    "Bcopy = copy(B)\n",
    "unsafe_diff!(Bcopy, Bcopy)\n",
    "[B[1];diff(B)] == Bcopy"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "If you really want to get your hands dirty, you can use the [SIMD.jl](https://github.com/eschnett/SIMD.jl)\n",
    "package to manually specify those `<8 x float>` things that LLVM generates.\n",
    "BUT: this is tricky and a pain; often it's just to be aware of what makes\n",
    "Julia code automatically SIMD-able, some of the cases where it may fail, and\n",
    "how to check its work."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## SIMD\n",
    "\n",
    "* Exploits built-in parallelism in a processor\n",
    "* Best for small, tight innermost loops\n",
    "* Often happens automatically if you're careful\n",
    "    * Follow the [perforance best practices](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "    * `@inbounds` any array acesses\n",
    "    * No branches or (non-inlined) function calls\n",
    "* Can use `@simd` to allow Julia to break some rules to make it happen\n",
    "    * But be careful, especially with `@simd ivdep`!\n",
    "* Depending on processor and types involved, can yield 2-16x gains with extraordinarily little overhead\n",
    "    * Smaller datatypes can improve this further; use `Float32` instead of `Float64`\n",
    "      if possible, `Int32` instead of `Int64`, etc.\n",
    "    * When buying a new processor, look for [AVX-512](https://en.wikichip.org/wiki/x86/avx-512) support"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
